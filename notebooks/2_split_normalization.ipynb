{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc634737",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfe3db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = pd.read_parquet('../data/model_data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907c910e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac3ea4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a84e53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data.drop(columns=['Patient ID', 'Follow-up #'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a231aa9",
   "metadata": {},
   "source": [
    "Now it's time for normalization. We want to do on the train dataset, after splitting data - to prevent data leakage, we don't want the information from val/test set in our model during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e03fda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "normalization_params = {\"min_age\": model_data['Patient Age'].min(),\n",
    "                        \"max_age\": model_data['Patient Age'].max()}\n",
    "\n",
    "model_data['PatientAge_norm'] = (model_data['Patient Age'] - model_data['Patient Age'].min()) / (model_data['Patient Age'].max() - model_data['Patient Age'].min())\n",
    "model_data.drop(columns=['Patient Age'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a76b83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84406477",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e19e68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c27853",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be58c7c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2685be7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1118089f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
