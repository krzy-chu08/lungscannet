{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc61d093",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from glob import glob\n",
    "from sklearn.metrics import f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e480b0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, we must define a class that will handle our dataset.\n",
    "\n",
    "class XRayDataset(Dataset):\n",
    "    def __init__(self, file_path, img_dir, transform=None):\n",
    "        self.df = pd.read_parquet(file_path)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        self.image_ids = self.df['image_id'].values\n",
    "        self.labels = self.df.iloc[:, 1:].values.astype(float)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = os.path.join(self.img_dir, self.image_ids[idx])\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e990f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2500/2500 [00:15<00:00, 160.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: [0.4965616762638092, 0.4965616762638092, 0.4965616762638092]\n",
      "Std: [0.24910806119441986, 0.24910806119441986, 0.24910806119441986]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Now it's time to find the params to normalize our images. We will do it using the `compute_mean_std` function.\n",
    "\n",
    "def compute_mean_std(image_dir, image_filenames, sample_size=1000):\n",
    "    transform = transforms.ToTensor()\n",
    "    \n",
    "    # Limit to sample_size\n",
    "    image_filenames = image_filenames[:sample_size]\n",
    "\n",
    "    sum_ = torch.zeros(3)\n",
    "    sum_squared = torch.zeros(3)\n",
    "    count = 0\n",
    "\n",
    "    for img_name in tqdm(image_filenames):\n",
    "        img_path = os.path.join(image_dir, img_name)\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        tensor = transform(img)\n",
    "        \n",
    "        sum_ += tensor.sum(dim=[1, 2])\n",
    "        sum_squared += (tensor ** 2).sum(dim=[1, 2])\n",
    "        count += tensor.shape[1] * tensor.shape[2]\n",
    "\n",
    "    mean = sum_ / count\n",
    "    std = (sum_squared / count - mean**2).sqrt()\n",
    "    return mean.tolist(), std.tolist()\n",
    "\n",
    "\n",
    "image_dir = \"../data/images/train\"\n",
    "image_files = [os.path.basename(p) for p in glob(f\"{image_dir}/*.png\")]\n",
    "random.shuffle(image_files)\n",
    "\n",
    "mean, std = compute_mean_std(image_dir, image_files, sample_size=2500)\n",
    "print(\"Mean:\", mean)\n",
    "print(\"Std:\", std)\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "# The code above would be used if we created the model from scratch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1d8bb2",
   "metadata": {},
   "source": [
    "We have to setup Transforms and DataLoaders. After doing so, we can setup our model. It's better to start with simpler model and see how it's doing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72f7ed58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_path = '../data'\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406], \n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "train_dataset = XRayDataset(f'{base_path}/train_df.parquet', f'{base_path}/images/train', transform=transform)\n",
    "val_dataset = XRayDataset(f'{base_path}/val_df.parquet', f'{base_path}/images/val', transform=transform)\n",
    "test_dataset = XRayDataset(f'{base_path}/test_df.parquet', f'{base_path}/images/test', transform=transform)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96482cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now it's time to choose a model. We will start with a pre-trained VGG16 model and modify it slightly to fit our needs.\n",
    "\n",
    "model = models.vgg16(weights='DEFAULT') \n",
    "model.classifier[6] = nn.Linear(4096, 18)  \n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "188aa26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2865e8e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 [Train]: 100%|██████████| 2786/2786 [6:53:12<00:00,  8.90s/it, acc=87.1, loss=0.241]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 87.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 [Val]: 100%|██████████| 370/370 [15:46<00:00,  2.56s/it, acc=87.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 87.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 [Train]: 100%|██████████| 2786/2786 [6:19:29<00:00,  8.17s/it, acc=88, loss=0.221]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 88.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 [Val]: 100%|██████████| 370/370 [19:02<00:00,  3.09s/it, acc=87.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 87.85%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 [Train]: 100%|██████████| 2786/2786 [7:50:27<00:00, 10.13s/it, acc=88.1, loss=0.218]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 88.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 [Val]: 100%|██████████| 370/370 [18:59<00:00,  3.08s/it, acc=87.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 87.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 [Train]: 100%|██████████| 2786/2786 [7:37:57<00:00,  9.86s/it, acc=88.2, loss=0.216]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 88.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 [Val]: 100%|██████████| 370/370 [19:04<00:00,  3.09s/it, acc=88]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 88.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 [Train]: 100%|██████████| 2786/2786 [7:58:15<00:00, 10.30s/it, acc=88.2, loss=0.214]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 88.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 [Val]: 100%|██████████| 370/370 [17:17<00:00,  2.80s/it, acc=88.1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 88.11%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    total_labels = 0\n",
    "    correct_labels = 0.0\n",
    "\n",
    "    train_loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\")\n",
    "    for images, labels in train_loop:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Multi-label accuracy\n",
    "        preds = torch.sigmoid(outputs)\n",
    "        predicted_labels = (preds > 0.5).float()\n",
    "        correct_labels += (predicted_labels == labels).sum().item()\n",
    "        total_labels += labels.numel()\n",
    "\n",
    "        # Update tqdm with dynamic stats\n",
    "        train_loop.set_postfix(loss=running_loss/len(train_loop), acc=100*correct_labels/total_labels)\n",
    "\n",
    "    train_acc = 100 * correct_labels / total_labels\n",
    "    print(f\"Train Accuracy: {train_acc:.2f}%\")\n",
    "\n",
    "    # ----- Validation -----\n",
    "    model.eval()\n",
    "    val_correct_labels = 0.0\n",
    "    val_total_labels = 0\n",
    "    val_loop = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Val]\")\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loop:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "\n",
    "            preds = torch.sigmoid(outputs)\n",
    "            predicted_labels = (preds > 0.5).float()\n",
    "            val_correct_labels += (predicted_labels == labels).sum().item()\n",
    "            val_total_labels += labels.numel()\n",
    "\n",
    "            val_loop.set_postfix(acc=100*val_correct_labels/val_total_labels)\n",
    "\n",
    "    val_acc = 100 * val_correct_labels / val_total_labels\n",
    "    print(f\"Validation Accuracy: {val_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e7684cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"vgg16_lungscan_v1.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19c6225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is a lot of room for improvement, the model barely learns anything. We will evaluate on the test set, see what's the issue and then try to use a different model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
